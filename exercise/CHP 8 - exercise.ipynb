{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier as CART\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = np.load('../data/iris_train_scaled.npz')\n",
    "X_train = arrays['X']\n",
    "y_train = arrays['y']\n",
    "arrays = np.load('../data/iris_test_scaled.npz')\n",
    "X_test = arrays['X']\n",
    "y_test = arrays['y']\n",
    "X_train = X_train[:, [0,1]]\n",
    "X_test = X_test[:, [0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf = [2, 10]\n",
    "n_estimators = [5, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for min_samples_leaf=2, n_estimators=5 on the test data is 0.733\n",
      "The accuracy for min_samples_leaf=2, n_estimators=20 on the test data is 0.767\n",
      "The accuracy for min_samples_leaf=10, n_estimators=5 on the test data is 0.633\n",
      "The accuracy for min_samples_leaf=10, n_estimators=20 on the test data is 0.633\n"
     ]
    }
   ],
   "source": [
    "for msl in min_samples_leaf:\n",
    "  cart = CART(min_samples_leaf=msl)\n",
    "  for n_est in n_estimators:\n",
    "    bagging = BaggingClassifier(estimator=cart, n_estimators=n_est)\n",
    "    bagging.fit(X_train, y_train)\n",
    "    score = bagging.score(X_test, y_test)\n",
    "    print('The accuracy for min_samples_leaf={}, n_estimators={} on the test data is {:.3f}'.format(msl, n_est, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for min_samples_leaf=2, n_estimators=5 on the test data is 0.700\n",
      "The accuracy for min_samples_leaf=2, n_estimators=20 on the test data is 0.767\n",
      "The accuracy for min_samples_leaf=10, n_estimators=5 on the test data is 0.667\n",
      "The accuracy for min_samples_leaf=10, n_estimators=20 on the test data is 0.700\n"
     ]
    }
   ],
   "source": [
    "for msl in min_samples_leaf:\n",
    "  for n_est in n_estimators:\n",
    "    rf = RandomForestClassifier(min_samples_leaf=msl, n_estimators=n_est)\n",
    "    rf.fit(X_train, y_train)\n",
    "    score = rf.score(X_test, y_test)\n",
    "    print('The accuracy for min_samples_leaf={}, n_estimators={} on the test data is {:.3f}'.format(msl, n_est, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for min_samples_leaf=2, n_estimators=5 on the test data is 0.633\n",
      "The accuracy for min_samples_leaf=2, n_estimators=20 on the test data is 0.767\n",
      "The accuracy for min_samples_leaf=10, n_estimators=5 on the test data is 0.633\n",
      "The accuracy for min_samples_leaf=10, n_estimators=20 on the test data is 0.633\n"
     ]
    }
   ],
   "source": [
    "for msl in min_samples_leaf:\n",
    "  cart = CART(min_samples_leaf=msl)\n",
    "  for n_est in n_estimators:\n",
    "    bagging = BaggingClassifier(estimator=cart, n_estimators=n_est, bootstrap=False, max_samples=0.5)\n",
    "    bagging.fit(X_train, y_train)\n",
    "    score = bagging.score(X_test, y_test)\n",
    "    print('The accuracy for min_samples_leaf={}, n_estimators={} on the test data is {:.3f}'.format(msl, n_est, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for min_samples_leaf=2, n_estimators=5 on the test data is 0.667\n",
      "The accuracy for min_samples_leaf=2, n_estimators=20 on the test data is 0.767\n",
      "The accuracy for min_samples_leaf=10, n_estimators=5 on the test data is 0.633\n",
      "The accuracy for min_samples_leaf=10, n_estimators=20 on the test data is 0.767\n"
     ]
    }
   ],
   "source": [
    "for msl in min_samples_leaf:\n",
    "  cart = CART(min_samples_leaf=msl)\n",
    "  for n_est in n_estimators:\n",
    "    boosting = AdaBoostClassifier(estimator=cart, n_estimators=n_est, algorithm='SAMME')\n",
    "    boosting.fit(X_train, y_train)\n",
    "    score = boosting.score(X_test, y_test)\n",
    "    print('The accuracy for min_samples_leaf={}, n_estimators={} on the test data is {:.3f}'.format(msl, n_est, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [5, 10]\n",
    "n_estimators = [5, 20, 100]\n",
    "\n",
    "# Convert data into DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for max_depth=5, n_estimators=5 on the test data is 0.767\n",
      "The accuracy for max_depth=5, n_estimators=20 on the test data is 0.767\n",
      "The accuracy for max_depth=5, n_estimators=100 on the test data is 0.767\n",
      "The accuracy for max_depth=10, n_estimators=5 on the test data is 0.767\n",
      "The accuracy for max_depth=10, n_estimators=20 on the test data is 0.767\n",
      "The accuracy for max_depth=10, n_estimators=100 on the test data is 0.733\n"
     ]
    }
   ],
   "source": [
    "for md in max_depth:\n",
    "  for n_est in n_estimators:\n",
    "    params = {\n",
    "        'objective': 'multi:softmax',  # Specify multiclass classification\n",
    "        'num_class': 3,  # Number of classes in the dataset\n",
    "        'max_depth': md,  # Maximum depth of the trees\n",
    "        'eta': 0.1,  # Learning rate\n",
    "        'gamma': 0.1,  # Minimum loss reduction required to make a further partition\n",
    "        'lambda': 1.0,  # L2 regularization term on weights\n",
    "        'eval_metric': 'mlogloss'  # Evaluation metric\n",
    "    }\n",
    "\n",
    "    bst = xgb.train(params, dtrain, n_est)\n",
    "    preds = bst.predict(dtest)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    print('The accuracy for max_depth={}, n_estimators={} on the test data is {:.3f}'.format(md, n_est, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
